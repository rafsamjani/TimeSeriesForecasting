{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Time Series Forecasting\n",
    "\n",
    "This notebook demonstrates using LSTM neural networks for time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.lstm_model import LSTMForecaster\n",
    "from src.utils.helpers import generate_sample_data, create_sequences\n",
    "from src.preprocessing.data_loader import train_test_split_ts\n",
    "from src.preprocessing.transformers import Normalizer\n",
    "from src.evaluation.metrics import calculate_metrics, print_metrics\n",
    "from src.visualization.plots import plot_forecast\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "data = generate_sample_data(n_samples=500, trend=True, seasonality=True)\n",
    "\n",
    "# Normalize data\n",
    "normalizer = Normalizer(method='minmax')\n",
    "data_normalized = normalizer.fit_transform(data.values)\n",
    "\n",
    "# Split into train and test\n",
    "split_idx = int(len(data_normalized) * 0.8)\n",
    "train_data = data_normalized[:split_idx]\n",
    "test_data = data_normalized[split_idx:]\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "n_steps = 30\n",
    "X_train, y_train = create_sequences(train_data, n_steps=n_steps)\n",
    "X_test, y_test = create_sequences(test_data, n_steps=n_steps)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build and Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "lstm_model = LSTMForecaster(\n",
    "    n_steps=n_steps,\n",
    "    n_features=1,\n",
    "    units=50,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "# Train model\n",
    "lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions_normalized = lstm_model.predict(X_test)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "predictions = normalizer.inverse_transform(predictions_normalized)\n",
    "y_test_original = normalizer.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "print(f\"Predictions shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "metrics = calculate_metrics(y_test_original.flatten(), predictions.flatten())\n",
    "print(\"LSTM Model Performance:\")\n",
    "print_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(y_test_original, label='Actual', linewidth=2, marker='o', markersize=3)\n",
    "plt.plot(predictions, label='Predicted', linewidth=2, linestyle='--', marker='x', markersize=3)\n",
    "plt.title('LSTM Forecast vs Actual', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time Step', fontsize=12)\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "history = lstm_model.history\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE', fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Preparing data for LSTM models\n",
    "- Building and training LSTM networks\n",
    "- Making forecasts with trained models\n",
    "- Evaluating model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
